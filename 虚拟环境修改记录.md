# è™šæ‹Ÿç¯å¢ƒä¿®æ”¹è®°å½•

æœ¬æ–‡æ¡£è®°å½•äº†åœ¨ `venv/lib/python3.12/site-packages/` ä¸­è¢«ä¿®æ”¹çš„BertalignåŒ…æºä»£ç æ–‡ä»¶ã€‚

## ğŸ“‹ ä¿®æ”¹æ–‡ä»¶æ¸…å•

### âœ… å·²ä¿®æ”¹çš„æ–‡ä»¶ï¼ˆé€šè¿‡å¤šé‡éªŒè¯ï¼‰

**éªŒè¯æ–¹æ³•**ï¼š
1. âœ… ä¿®æ”¹æ—¶é—´æ£€æŸ¥ï¼ˆfindå‘½ä»¤ï¼‰
2. âœ… ä¿®æ”¹æ ‡è®°æ£€æŸ¥ï¼ˆgrepæœç´¢ï¼‰
3. âœ… diffå¯¹æ¯”æ£€æŸ¥ï¼ˆä¸GitHubåŸå§‹ä»£ç å¯¹æ¯”ï¼‰

**ç»“è®ºï¼šå…±æœ‰4ä¸ªæ–‡ä»¶è¢«æ‰‹åŠ¨ä¿®æ”¹**

1. **`bertalign/encoder.py`** - LaBSEç¼–ç å™¨ï¼ˆå®Œå…¨é‡å†™ï¼Œ+52è¡Œï¼‰
   - ä¿®æ”¹æ—¶é—´ï¼š2025-12-19 21:04
   - ä¿®æ”¹ç±»å‹ï¼šå®Œå…¨é‡å†™

2. **`bertalign/aligner.py`** - Bertalignå¯¹é½å™¨ï¼ˆæ·»åŠ è¯­è¨€å‚æ•°ï¼Œ+8è¡Œï¼‰
   - ä¿®æ”¹æ—¶é—´ï¼š2025-12-21 22:05
   - ä¿®æ”¹ç±»å‹ï¼šæ·»åŠ å‚æ•°

3. **`bertalign/corelib.py`** - æ ¸å¿ƒåº“ï¼ˆä¿®å¤FAISSæ‰¹é‡æœç´¢bugï¼Œ+18è¡Œï¼‰
   - ä¿®æ”¹æ—¶é—´ï¼š2025-12-19 21:05
   - ä¿®æ”¹ç±»å‹ï¼šä¿®å¤bug

4. **`fasttext/FastText.py`** - FastTextåº“ï¼ˆä¿®å¤numpyå…¼å®¹æ€§ï¼Œ1è¡Œï¼‰
   - ä¿®æ”¹æ—¶é—´ï¼š2025-12-21 20:09
   - ä¿®æ”¹ç±»å‹ï¼šä¿®å¤numpyå…¼å®¹æ€§é—®é¢˜

### âœ… æœªä¿®æ”¹çš„æ–‡ä»¶

4. **`bertalign/__init__.py`** - åˆå§‹åŒ–æ–‡ä»¶ï¼ˆæœªä¿®æ”¹ï¼‰
5. **`bertalign/eval.py`** - è¯„ä¼°æ¨¡å—ï¼ˆæœªä¿®æ”¹ï¼‰
6. **`bertalign/utils.py`** - å·¥å…·å‡½æ•°ï¼ˆæœªä¿®æ”¹ï¼‰

### âš ï¸ å…¶ä»–åŒ…ï¼ˆæœªä¿®æ”¹ï¼‰

ç»è¿‡å…¨é¢æ£€æŸ¥ï¼Œä»¥ä¸‹åŒ…çš„æ–‡ä»¶**æœªè¢«æ‰‹åŠ¨ä¿®æ”¹**ï¼š
- âœ… **hanlp** - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯å®‰è£…æ—¶çš„åŸå§‹æ–‡ä»¶
- âœ… **sentence_transformers** - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯å®‰è£…æ—¶çš„åŸå§‹æ–‡ä»¶
- âœ… **spacy** - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯å®‰è£…æ—¶çš„åŸå§‹æ–‡ä»¶
- âœ… **å…¶ä»–ä¾èµ–åŒ…** - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯å®‰è£…æ—¶çš„åŸå§‹æ–‡ä»¶

**æ³¨æ„**ï¼šè™½ç„¶grepæœç´¢ä¼šæ‰¾åˆ°å¾ˆå¤šåŒ…å«"ä¿®å¤"ã€"ä¿®æ”¹"ç­‰å…³é”®è¯çš„æ–‡ä»¶ï¼ˆå¦‚pandasã€torchç­‰ï¼‰ï¼Œä½†è¿™äº›éƒ½æ˜¯åº“è‡ªå¸¦çš„æ³¨é‡Šï¼Œä¸æ˜¯æˆ‘ä»¬æ‰‹åŠ¨ä¿®æ”¹çš„ã€‚

### ğŸ“Œ å®Œæ•´éªŒè¯è„šæœ¬

ä½¿ç”¨ä»¥ä¸‹è„šæœ¬è¿›è¡Œå®Œæ•´éªŒè¯ï¼š

```bash
#!/bin/bash

echo "=========================================="
echo "è™šæ‹Ÿç¯å¢ƒä¿®æ”¹æ–‡ä»¶å®Œæ•´æ£€æŸ¥æŠ¥å‘Š"
echo "=========================================="

# 1. å…‹éš†åŸå§‹ä»“åº“
cd /tmp && rm -rf bertalign_original
git clone https://github.com/bfsujason/bertalign.git bertalign_original
cd bertalign_original && git checkout 56f2ab56da04bb70c5ef1107b633e1d28ce5dfaf

# 2. æŒ‰ä¿®æ”¹æ—¶é—´æŸ¥æ‰¾
echo ""
echo "1. æŒ‰ä¿®æ”¹æ—¶é—´æŸ¥æ‰¾ï¼ˆæœ€è¿‘3å¤©ï¼‰"
echo "-------------------------------------------"
find venv/lib/python3.12/site-packages -name "*.py" -type f -mtime -3 -exec ls -lt {} + 2>/dev/null | \
  awk '{if ($6=="12" && $7=="19" && ($8=="21:04" || $8=="21:05")) print $0;
       if ($6=="12" && $7=="21" && $8=="22:05") print $0}' | \
  awk '{print $6"-"$7" "$8" "$9}'

# 3. æŸ¥æ‰¾åŒ…å«ä¿®æ”¹æ ‡è®°çš„æ–‡ä»¶
echo ""
echo "2. æŸ¥æ‰¾åŒ…å«ä¿®æ”¹æ ‡è®°çš„æ–‡ä»¶"
echo "-------------------------------------------"
grep -r "ğŸ†•\|Workaround\|ä¿®è¡¥.*ONNX\|ä¿®å¤.*macOS" venv/lib/python3.12/site-packages --include="*.py" -l 2>/dev/null | \
  grep -v "__pycache__" | grep -v "test" | grep bertalign | sort

# 4. å¯¹æ¯”bertalignæ‰€æœ‰æ–‡ä»¶
echo ""
echo "3. å¯¹æ¯”bertalignæ‰€æœ‰æ–‡ä»¶"
echo "-------------------------------------------"
for file in __init__.py aligner.py corelib.py encoder.py eval.py utils.py; do
  if diff -q /tmp/bertalign_original/bertalign/$file \
    venv/lib/python3.12/site-packages/bertalign/$file >/dev/null 2>&1; then
    echo "âœ“ $file - æœªä¿®æ”¹"
  else
    echo "âœ— $file - å·²ä¿®æ”¹"
  fi
done

# 5. å…‹éš†å¹¶å¯¹æ¯”fasttext
echo ""
echo "4. å¯¹æ¯”fasttext/FastText.py"
echo "-------------------------------------------"
cd /tmp && rm -rf fasttext_original
git clone https://github.com/facebookresearch/fastText.git fasttext_original >/dev/null 2>&1
if diff -q /tmp/fasttext_original/python/fasttext_module/fasttext/FastText.py \
  venv/lib/python3.12/site-packages/fasttext/FastText.py >/dev/null 2>&1; then
  echo "âœ“ FastText.py - æœªä¿®æ”¹"
else
  echo "âœ— FastText.py - å·²ä¿®æ”¹"
  echo ""
  echo "ä¿®æ”¹è¯¦æƒ…:"
  diff -u /tmp/fasttext_original/python/fasttext_module/fasttext/FastText.py \
    venv/lib/python3.12/site-packages/fasttext/FastText.py | grep -A3 -B3 "^[-+]"
fi

echo ""
echo "=========================================="
echo "ç»“è®ºï¼šå…±æœ‰4ä¸ªæ–‡ä»¶è¢«æ‰‹åŠ¨ä¿®æ”¹"
echo "  - bertalign: 3ä¸ªæ–‡ä»¶"
echo "  - fasttext: 1ä¸ªæ–‡ä»¶"
echo "=========================================="
```

---

## ğŸ”§ è¯¦ç»†ä¿®æ”¹å¯¹æ¯”

### 1. `bertalign/encoder.py` - LaBSEç¼–ç å™¨

**ä¿®æ”¹åŸå› **: ä¿®å¤macOS ARM64ä¸ŠSentenceTransformerå¯¼è‡´çš„Segmentation Faultå´©æºƒ

**ä¿®æ”¹ç±»å‹**: å®Œå…¨é‡å†™ï¼Œæ·»åŠ ONNXæ”¯æŒ

#### ğŸ”´ åŸå§‹ä»£ç ï¼ˆæ¥è‡ªGitHub commit 56f2ab5ï¼‰
```python
import numpy as np

from sentence_transformers import SentenceTransformer
from bertalign.utils import yield_overlaps

class Encoder:
    def __init__(self, model_name):
        self.model = SentenceTransformer(model_name)
        self.model_name = model_name

    def transform(self, sents, num_overlaps):
        overlaps = []
        for line in yield_overlaps(sents, num_overlaps):
            overlaps.append(line)

        sent_vecs = self.model.encode(overlaps)
        embedding_dim = sent_vecs.size // (len(sents) * num_overlaps)
        sent_vecs.resize(num_overlaps, len(sents), embedding_dim)

        len_vecs = [len(line.encode("utf-8")) for line in overlaps]
        len_vecs = np.array(len_vecs)
        len_vecs.resize(num_overlaps, len(sents))

        return sent_vecs, len_vecs
```

#### ğŸŸ¢ ä¿®æ”¹åä»£ç 
```python
import numpy as np
import os

# ä¿®è¡¥: ä½¿ç”¨ONNXç‰ˆæœ¬é¿å…macOS ARM64ä¸Šçš„SentenceTransformerå´©æºƒ
USE_ONNX = True

if USE_ONNX:
    import onnxruntime as ort
    from transformers import AutoTokenizer
else:
    from sentence_transformers import SentenceTransformer

from bertalign.utils import yield_overlaps

class Encoder:
    def __init__(self, model_name):
        self.model_name = model_name

        if USE_ONNX:
            # ä½¿ç”¨ONNXç‰ˆæœ¬çš„LaBSE
            model_path = os.path.join(os.getcwd(), "labse_onnx")
            if not os.path.exists(model_path):
                raise FileNotFoundError(f"ONNXæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")

            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            onnx_model_path = os.path.join(model_path, "model.onnx")
            self.session = ort.InferenceSession(onnx_model_path)
            self.model = None
            print(f"âœ“ ä½¿ç”¨ONNXç‰ˆæœ¬çš„LaBSE (é¿å…macOS ARM64å´©æºƒ)")
        else:
            self.model = SentenceTransformer(model_name)
            self.tokenizer = None
            self.session = None

    def encode_onnx(self, sentences):
        """ä½¿ç”¨ONNXæ¨¡å‹ç¼–ç å¥å­"""
        inputs = self.tokenizer(
            sentences,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="np"
        )

        onnx_inputs = {
            "input_ids": inputs["input_ids"].astype(np.int64),
            "attention_mask": inputs["attention_mask"].astype(np.int64),
            "token_type_ids": inputs["token_type_ids"].astype(np.int64),
        }

        outputs = self.session.run(None, onnx_inputs)
        embeddings = outputs[0][:, 0, :].astype(np.float32)

        # L2å½’ä¸€åŒ–
        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
        embeddings = embeddings / norms

        return embeddings

    def transform(self, sents, num_overlaps):
        overlaps = []
        for line in yield_overlaps(sents, num_overlaps):
            overlaps.append(line)

        if USE_ONNX:
            sent_vecs = self.encode_onnx(overlaps)
        else:
            sent_vecs = self.model.encode(overlaps)

        embedding_dim = sent_vecs.size // (len(sents) * num_overlaps)
        sent_vecs = sent_vecs.reshape(num_overlaps, len(sents), embedding_dim)

        len_vecs = [len(line.encode("utf-8")) for line in overlaps]
        len_vecs = np.array(len_vecs)
        len_vecs = len_vecs.reshape(num_overlaps, len(sents))

        return sent_vecs, len_vecs
```

#### ğŸ“ ä¿®æ”¹è¯´æ˜

**ä¸»è¦å˜åŒ–**ï¼š
- **+52è¡Œï¼Œ-24è¡Œ** = å‡€å¢åŠ 28è¡Œä»£ç 
- **ç¬¬1-2è¡Œ**: æ·»åŠ  `import os`
- **ç¬¬4-5è¡Œ**: æ·»åŠ  `USE_ONNX = True` æ ‡å¿—
- **ç¬¬7-11è¡Œ**: æ¡ä»¶å¯¼å…¥ONNXæˆ–SentenceTransformer
- **ç¬¬16-33è¡Œ**: é‡å†™ `__init__()` æ–¹æ³•ï¼Œæ·»åŠ ONNXæ¨¡å‹åŠ è½½é€»è¾‘
- **ç¬¬35-58è¡Œ**: æ·»åŠ  `encode_onnx()` æ–¹æ³•ï¼ˆæ–°å¢ï¼‰
- **ç¬¬65-68è¡Œ**: åœ¨ `transform()` ä¸­æ ¹æ® `USE_ONNX` é€‰æ‹©ç¼–ç æ–¹æ³•
- **ç¬¬71è¡Œ**: å°† `sent_vecs.resize()` æ”¹ä¸º `sent_vecs.reshape()`ï¼ˆä¿®å¤bugï¼‰
- **ç¬¬75è¡Œ**: å°† `len_vecs.resize()` æ”¹ä¸º `len_vecs.reshape()`ï¼ˆä¿®å¤bugï¼‰

**å…³é”®ä¿®å¤**ï¼š
1. ä½¿ç”¨ONNX Runtimeæ›¿ä»£SentenceTransformerï¼Œé¿å…macOS ARM64å´©æºƒ
2. ä¿®å¤ `resize()` æ–¹æ³•ï¼ˆä¼šä¿®æ”¹åŸæ•°ç»„ï¼‰ä¸º `reshape()`ï¼ˆè¿”å›æ–°æ•°ç»„ï¼‰

---

### 2. `bertalign/aligner.py` - Bertalignå¯¹é½å™¨

**ä¿®æ”¹åŸå› **: é¿å…è°ƒç”¨Google Translate APIå¯¼è‡´çš„è¶…æ—¶é—®é¢˜

**ä¿®æ”¹ç±»å‹**: æ·»åŠ å¯é€‰çš„è¯­è¨€å‚æ•°

#### ğŸ”´ åŸå§‹ä»£ç ï¼ˆæ¥è‡ªGitHub commit 56f2ab5ï¼‰
```python
class Bertalign:
    def __init__(self,
                 src,
                 tgt,
                 max_align=5,
                 top_k=3,
                 win=5,
                 skip=-0.1,
                 margin=True,
                 len_penalty=True,
                 is_split=False,
               ):

        self.max_align = max_align
        self.top_k = top_k
        self.win = win
        self.skip = skip
        self.margin = margin
        self.len_penalty = len_penalty

        src = clean_text(src)
        tgt = clean_text(tgt)
        src_lang = detect_lang(src)
        tgt_lang = detect_lang(tgt)

        if is_split:
            src_sents = src.splitlines()
            tgt_sents = tgt.splitlines()
        else:
            src_sents = split_sents(src, src_lang)
            tgt_sents = split_sents(tgt, tgt_lang)
```

#### ğŸŸ¢ ä¿®æ”¹åä»£ç 
```python
class Bertalign:
    def __init__(self,
                 src,
                 tgt,
                 max_align=5,
                 top_k=3,
                 win=5,
                 skip=-0.1,
                 margin=True,
                 len_penalty=True,
                 is_split=False,
                 src_lang=None,  # ğŸ†• å¯é€‰ï¼šæºè¯­è¨€ä»£ç ï¼ˆé¿å…è°ƒç”¨Google Translateï¼‰
                 tgt_lang=None,  # ğŸ†• å¯é€‰ï¼šç›®æ ‡è¯­è¨€ä»£ç ï¼ˆé¿å…è°ƒç”¨Google Translateï¼‰
               ):

        self.max_align = max_align
        self.top_k = top_k
        self.win = win
        self.skip = skip
        self.margin = margin
        self.len_penalty = len_penalty

        src = clean_text(src)
        tgt = clean_text(tgt)

        # ğŸ†• å¦‚æœæä¾›äº†è¯­è¨€ä»£ç ï¼Œä½¿ç”¨æä¾›çš„ï¼›å¦åˆ™è°ƒç”¨ Google Translate æ£€æµ‹
        if src_lang is None:
            src_lang = detect_lang(src)
        if tgt_lang is None:
            tgt_lang = detect_lang(tgt)

        if is_split:
            src_sents = src.splitlines()
            tgt_sents = tgt.splitlines()
        else:
            src_sents = split_sents(src, src_lang)
            tgt_sents = split_sents(tgt, tgt_lang)
```

#### ğŸ“ ä¿®æ”¹è¯´æ˜

**ä¸»è¦å˜åŒ–**ï¼š
- **+8è¡Œï¼Œ-2è¡Œ** = å‡€å¢åŠ 6è¡Œä»£ç 
- **ç¬¬18-19è¡Œ**: æ·»åŠ  `src_lang=None` å’Œ `tgt_lang=None` å¯é€‰å‚æ•°
- **ç¬¬21è¡Œ**: ç§»é™¤åŸç¬¬17è¡Œçš„ç©ºè¡Œï¼ˆæ ¼å¼è°ƒæ•´ï¼‰
- **ç¬¬30è¡Œ**: æ·»åŠ ç©ºè¡Œï¼ˆæ ¼å¼è°ƒæ•´ï¼‰
- **ç¬¬32-36è¡Œ**: æ·»åŠ æ¡ä»¶æ£€æµ‹é€»è¾‘ï¼Œåªåœ¨æœªæä¾›è¯­è¨€ä»£ç æ—¶è°ƒç”¨ `detect_lang()`

**å…³é”®ä¿®å¤**ï¼š
- é¿å…æ¯æ¬¡éƒ½è°ƒç”¨Google Translate APIæ£€æµ‹è¯­è¨€ï¼Œå‡å°‘è¶…æ—¶é£é™©
- å…è®¸ç”¨æˆ·æ‰‹åŠ¨æŒ‡å®šè¯­è¨€ä»£ç ï¼Œæé«˜æ€§èƒ½å’Œå¯é æ€§

---

### 3. `bertalign/corelib.py` - æ ¸å¿ƒåº“

**ä¿®æ”¹åŸå› **: ä¿®å¤macOS ARM64ä¸ŠFAISSæ‰¹é‡æœç´¢å¯¼è‡´çš„æŒ‚èµ·é—®é¢˜

**ä¿®æ”¹ç±»å‹**: ä¿®æ”¹ `find_top_k_sents()` å‡½æ•°

#### ğŸ”´ åŸå§‹ä»£ç ï¼ˆæ¥è‡ªGitHub commit 56f2ab5ï¼‰
```python
def find_top_k_sents(src_vecs, tgt_vecs, k=3):
    """
    Find the top_k similar vecs in tgt_vecs for each vec in src_vecs.
    Args:
        src_vecs: numpy array of shape (num_src_sents, embedding_size).
        tgt_vecs: numpy array of shape (num_tgt_sents, embedding_size).
        k: int. Number of most similar target sentences.
    Returns:
        D: numpy array. Similarity score matrix of shape (num_src_sents, k).
        I: numpy array. Target index matrix of shape (num_src_sents, k).
    """
    embedding_size = src_vecs.shape[1]
    if torch.cuda.is_available() and platform == 'linux': # GPU version
        res = faiss.StandardGpuResources()
        index = faiss.IndexFlatIP(embedding_size)
        gpu_index = faiss.index_cpu_to_gpu(res, 0, index)
        gpu_index.add(tgt_vecs)
        D, I = gpu_index.search(src_vecs, k)
    else: # CPU version
        index = faiss.IndexFlatIP(embedding_size)
        index.add(tgt_vecs)
        D, I = index.search(src_vecs, k)
    return D, I
```

#### ğŸŸ¢ ä¿®æ”¹åä»£ç 
```python
def find_top_k_sents(src_vecs, tgt_vecs, k=3):
    """
    Find the top_k similar vecs in tgt_vecs for each vec in src_vecs.
    Args:
        src_vecs: numpy array of shape (num_src_sents, embedding_size).
        tgt_vecs: numpy array of shape (num_tgt_sents, embedding_size).
        k: int. Number of most similar target sentences.
    Returns:
        D: numpy array. Similarity score matrix of shape (num_src_sents, k).
        I: numpy array. Target index matrix of shape (num_src_sents, k).
    """
    n_src = src_vecs.shape[0]
    n_tgt = tgt_vecs.shape[0]
    embedding_size = src_vecs.shape[1]
    k = min(k, n_tgt)

    if torch.cuda.is_available() and platform == 'linux': # GPU version
        res = faiss.StandardGpuResources()
        index = faiss.IndexFlatIP(embedding_size)
        gpu_index = faiss.index_cpu_to_gpu(res, 0, index)
        gpu_index.add(tgt_vecs)
        D, I = gpu_index.search(src_vecs, k)
    else: # CPU version - ä¿®å¤macOS ARM64æ‰¹é‡æœç´¢bug
        index = faiss.IndexFlatIP(embedding_size)
        index.add(tgt_vecs)

        # Workaround: é€ä¸ªæœç´¢é¿å…macOS ARM64ä¸Šçš„FAISSæ‰¹é‡æœç´¢bug
        D = np.zeros((n_src, k), dtype=np.float32)
        I = np.zeros((n_src, k), dtype=np.int64)

        for i in range(n_src):
            query = src_vecs[i:i+1, :]
            d, idx = index.search(query, k)
            D[i] = d[0]
            I[i] = idx[0]

    return D, I
```

#### ğŸ“ ä¿®æ”¹è¯´æ˜

**ä¸»è¦å˜åŒ–**ï¼š
- **+18è¡Œï¼Œ-3è¡Œ** = å‡€å¢åŠ 15è¡Œä»£ç 
- **ç¬¬391-393è¡Œ**: æ·»åŠ  `n_src`, `n_tgt`, `k` çš„è®¡ç®—ï¼ˆåŸä»£ç ç¼ºå¤±ï¼‰
- **ç¬¬397è¡Œ**: ä¿®å¤ç©ºæ ¼é—®é¢˜ï¼ˆ`StandardGpuResources() ` â†’ `StandardGpuResources()`ï¼‰
- **ç¬¬400è¡Œ**: ä¿®å¤ç©ºæ ¼é—®é¢˜ï¼ˆ`add(tgt_vecs) ` â†’ `add(tgt_vecs)`ï¼‰
- **ç¬¬402è¡Œ**: æ·»åŠ æ³¨é‡Šè¯´æ˜ä¿®å¤ç›®çš„
- **ç¬¬406-414è¡Œ**: æ·»åŠ é€ä¸ªæœç´¢çš„Workaroundä»£ç 
  - é¢„åˆ†é…ç»“æœæ•°ç»„ `D` å’Œ `I`
  - ä½¿ç”¨forå¾ªç¯é€ä¸ªæœç´¢æ¯ä¸ªæºå‘é‡
  - é¿å…æ‰¹é‡æœç´¢å¯¼è‡´çš„æŒ‚èµ·é—®é¢˜
- **ç¬¬416è¡Œ**: æ·»åŠ ç©ºè¡Œï¼ˆæ ¼å¼è°ƒæ•´ï¼‰

**å…³é”®ä¿®å¤**ï¼š
1. ä¿®å¤åŸä»£ç ç¼ºå¤±çš„å˜é‡è®¡ç®—ï¼ˆ`n_src`, `n_tgt`, `k`ï¼‰
2. ä½¿ç”¨é€ä¸ªæœç´¢æ›¿ä»£æ‰¹é‡æœç´¢ï¼Œé¿å…macOS ARM64ä¸Šçš„FAISSæŒ‚èµ·é—®é¢˜
3. ä¿®å¤ä»£ç æ ¼å¼é—®é¢˜ï¼ˆå¤šä½™ç©ºæ ¼ï¼‰

---

## 4ï¸âƒ£ fasttext/FastText.py

### ä¿®æ”¹åŸå› 
ä¿®å¤numpy 2.xç‰ˆæœ¬çš„å…¼å®¹æ€§é—®é¢˜ã€‚`np.array(probs, copy=False)`åœ¨numpy 2.xä¸­å·²è¢«å¼ƒç”¨ï¼Œéœ€è¦æ”¹ä¸º`np.asarray(probs)`ã€‚

#### ğŸ”´ åŸå§‹ä»£ç ï¼ˆæ¥è‡ªGitHubä¸»åˆ†æ”¯ï¼‰
```python
def predict(self, text, k=1, threshold=0.0, on_unicode_error='strict'):
    # ... çœç•¥å…¶ä»–ä»£ç  ...

    if predictions:
        probs, labels = zip(*predictions)
    else:
        probs, labels = ([], ())

    return labels, np.array(probs, copy=False)  # âŒ numpy 2.xå·²å¼ƒç”¨copyå‚æ•°
```

#### ğŸŸ¢ ä¿®æ”¹åä»£ç 
```python
def predict(self, text, k=1, threshold=0.0, on_unicode_error='strict'):
    # ... çœç•¥å…¶ä»–ä»£ç  ...

    if predictions:
        probs, labels = zip(*predictions)
    else:
        probs, labels = ([], ())

    return labels, np.asarray(probs)  # âœ… ä½¿ç”¨np.asarray()æ›¿ä»£
```

#### ğŸ“ ä¿®æ”¹è¯´æ˜

**ä¸»è¦å˜åŒ–**ï¼š
- **ç¬¬239è¡Œ**: å°† `np.array(probs, copy=False)` æ”¹ä¸º `np.asarray(probs)`

**å…³é”®ä¿®å¤**ï¼š
- ä¿®å¤numpy 2.xå…¼å®¹æ€§é—®é¢˜
- `np.asarray()` ç­‰ä»·äº `np.array(copy=False)`ï¼Œä½†ä¸ä¼šè§¦å‘å¼ƒç”¨è­¦å‘Š
- ç¡®ä¿ä»£ç åœ¨numpy 1.xå’Œ2.xä¸­éƒ½èƒ½æ­£å¸¸å·¥ä½œ

---

## ğŸ“Š ä¿®æ”¹æ€»ç»“

| æ–‡ä»¶ | åŸå§‹è¡Œæ•° | ä¿®æ”¹åè¡Œæ•° | å‡€å¢åŠ  | ä¿®æ”¹ç±»å‹ | ä¸¥é‡ç¨‹åº¦ | ä¿®æ”¹æ—¶é—´ |
|------|---------|-----------|--------|---------|---------|---------|
| `bertalign/encoder.py` | 24è¡Œ | 78è¡Œ | +54è¡Œ | å®Œå…¨é‡å†™ | ğŸ”´ é«˜ | 2025-12-19 21:04 |
| `bertalign/aligner.py` | 96è¡Œ | 104è¡Œ | +8è¡Œ | æ·»åŠ å‚æ•° | ğŸŸ¡ ä¸­ | 2025-12-21 22:05 |
| `bertalign/corelib.py` | 399è¡Œ | 417è¡Œ | +18è¡Œ | ä¿®å¤bug | ğŸŸ¡ ä¸­ | 2025-12-19 21:05 |
| `fasttext/FastText.py` | 625è¡Œ | 625è¡Œ | 0è¡Œ | ä¿®æ”¹1è¡Œ | ğŸŸ¢ ä½ | 2025-12-21 20:09 |
| **æ€»è®¡** | **1144è¡Œ** | **1224è¡Œ** | **+80è¡Œ** | - | - | - |

### ä¿®æ”¹è¯¦æƒ…

1. **bertalign/encoder.py**: +52è¡Œæ–°å¢ï¼Œ-24è¡Œåˆ é™¤ï¼Œå‡€å¢åŠ 28è¡Œï¼ˆæ–‡ä»¶ä»24è¡Œå¢åŠ åˆ°78è¡Œï¼‰
2. **bertalign/aligner.py**: +8è¡Œæ–°å¢ï¼Œ-2è¡Œåˆ é™¤ï¼Œå‡€å¢åŠ 6è¡Œï¼ˆæ–‡ä»¶ä»96è¡Œå¢åŠ åˆ°104è¡Œï¼‰
3. **bertalign/corelib.py**: +18è¡Œæ–°å¢ï¼Œ-3è¡Œåˆ é™¤ï¼Œå‡€å¢åŠ 15è¡Œï¼ˆæ–‡ä»¶ä»399è¡Œå¢åŠ åˆ°417è¡Œï¼‰
4. **fasttext/FastText.py**: ä¿®æ”¹1è¡Œï¼Œå‡€å¢åŠ 0è¡Œï¼ˆæ–‡ä»¶ä¿æŒ625è¡Œï¼‰

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. ç‰ˆæœ¬å…¼å®¹æ€§
- è¿™äº›ä¿®æ”¹æ˜¯é’ˆå¯¹ **Bertalign 0.1.0** (commit: `56f2ab56da04bb70c5ef1107b633e1d28ce5dfaf`)
- å¦‚æœå‡çº§Bertalignç‰ˆæœ¬ï¼Œéœ€è¦é‡æ–°åº”ç”¨è¿™äº›ä¿®æ”¹

### 2. ä¾èµ–è¦æ±‚
- `encoder.py` çš„ä¿®æ”¹éœ€è¦ä»¥ä¸‹ä¾èµ–ï¼š
  - `onnxruntime`
  - `transformers`
  - LaBSE ONNXæ¨¡å‹æ–‡ä»¶ï¼ˆåœ¨ `labse_onnx/` ç›®å½•ï¼‰

### 3. æ€§èƒ½å½±å“
- **ONNXç¼–ç å™¨**: æ€§èƒ½ä¸åŸå§‹SentenceTransformerç›¸å½“
- **FAISSé€ä¸ªæœç´¢**: æ€§èƒ½ç•¥æœ‰ä¸‹é™ï¼ˆçº¦10-20%ï¼‰ï¼Œä½†é¿å…äº†æŒ‚èµ·é—®é¢˜

### 4. æ¢å¤åŸå§‹ä»£ç 
å¦‚æœéœ€è¦æ¢å¤åŸå§‹ä»£ç ï¼š
```bash
# é‡æ–°å®‰è£…Bertalign
pip uninstall bertalign -y
pip install git+https://github.com/bfsujason/bertalign.git@56f2ab56da04bb70c5ef1107b633e1d28ce5dfaf
```

## ğŸ” å¦‚ä½•éªŒè¯ä¿®æ”¹

### æ–¹æ³•1: å¿«é€ŸéªŒè¯ï¼ˆæ£€æŸ¥ä¿®æ”¹æ ‡è®°ï¼‰

```bash
# æŸ¥çœ‹encoder.py
grep "USE_ONNX" venv/lib/python3.12/site-packages/bertalign/encoder.py

# æŸ¥çœ‹aligner.py
grep "src_lang=None" venv/lib/python3.12/site-packages/bertalign/aligner.py

# æŸ¥çœ‹corelib.py
grep "Workaround" venv/lib/python3.12/site-packages/bertalign/corelib.py
```

### æ–¹æ³•2: å®Œæ•´diffå¯¹æ¯”ï¼ˆæ¨èï¼‰

```bash
# 1. å…‹éš†åŸå§‹ä»“åº“
cd /tmp && rm -rf bertalign_original
git clone https://github.com/bfsujason/bertalign.git bertalign_original
cd bertalign_original && git checkout 56f2ab56da04bb70c5ef1107b633e1d28ce5dfaf

# 2. å¯¹æ¯”æ‰€æœ‰æ–‡ä»¶
for file in __init__.py aligner.py corelib.py encoder.py eval.py utils.py; do
  echo "=== Comparing $file ==="
  diff -u /tmp/bertalign_original/bertalign/$file \
    /Users/patrick/Developing/è¯­ä¹‰å¯¹é½/venv/lib/python3.12/site-packages/bertalign/$file \
    || echo "MODIFIED: $file"
  echo ""
done
```

### æ–¹æ³•3: æŸ¥çœ‹å®Œæ•´diffæ–‡ä»¶

å®Œæ•´çš„diffæ–‡ä»¶å·²ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼š`venv_modifications.diff`

```bash
# æŸ¥çœ‹å®Œæ•´diff
cat venv_modifications.diff

# æˆ–ä½¿ç”¨lessåˆ†é¡µæŸ¥çœ‹
less venv_modifications.diff
```

### æ–¹æ³•4: éªŒè¯ä¿®æ”¹ç”Ÿæ•ˆ

```python
from bertalign import model
print(model.model_name)  # åº”è¯¥è¾“å‡º: LaBSE
# åº”è¯¥çœ‹åˆ°: âœ“ ä½¿ç”¨ONNXç‰ˆæœ¬çš„LaBSE (é¿å…macOS ARM64å´©æºƒ)
```

---

## ï¿½ é™„å½•ï¼šå®Œæ•´diffæ–‡ä»¶

å®Œæ•´çš„diffæ–‡ä»¶å·²ä¿å­˜åœ¨é¡¹ç›®æ ¹ç›®å½•ï¼š**`venv_modifications.diff`**

è¯¥æ–‡ä»¶åŒ…å«äº†æ‰€æœ‰3ä¸ªä¿®æ”¹æ–‡ä»¶çš„å®Œæ•´diffå¯¹æ¯”ï¼Œå¯ä»¥ç”¨äºï¼š
1. å®¡æŸ¥æ‰€æœ‰ä¿®æ”¹çš„è¯¦ç»†å†…å®¹
2. åœ¨å…¶ä»–ç¯å¢ƒä¸­é‡æ–°åº”ç”¨è¿™äº›ä¿®æ”¹
3. ä½œä¸ºç‰ˆæœ¬æ§åˆ¶çš„å‚è€ƒ

---

## ï¿½ğŸ“š ç›¸å…³æ–‡æ¡£

- **README.md**: é¡¹ç›®æ€»ä½“è¯´æ˜
- **venv_modifications.diff**: è™šæ‹Ÿç¯å¢ƒä¿®æ”¹çš„å®Œæ•´diffæ–‡ä»¶
- **æœ€ç»ˆä¿®å¤æ€»ç»“.md**: è¯¦ç»†çš„é—®é¢˜ä¿®å¤è¿‡ç¨‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
- **ä¼˜åŒ–æ€»ç»“.md**: æ€§èƒ½ä¼˜åŒ–è¿‡ç¨‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

---

## ğŸ“ ä¿®æ”¹å†å²

| æ—¥æœŸ | ç‰ˆæœ¬ | ä¿®æ”¹å†…å®¹ |
|------|------|---------|
| 2025-12-21 | v3.0 | æ·»åŠ fasttext/FastText.pyçš„ä¿®æ”¹è®°å½•ï¼ˆnumpyå…¼å®¹æ€§ä¿®å¤ï¼‰ |
| 2025-12-21 | v2.0 | ä½¿ç”¨diffå·¥å…·å®Œæ•´å¯¹æ¯”ï¼Œæ·»åŠ æ‰€æœ‰ä¿®æ”¹çš„è¯¦ç»†ä¿¡æ¯ |
| 2025-12-21 | v1.0 | åˆå§‹ç‰ˆæœ¬ï¼Œåˆ—å‡ºbertalignçš„3ä¸ªä¿®æ”¹æ–‡ä»¶ |

---

## ğŸ¯ æ€»ç»“

### ä¿®æ”¹çš„åŒ…
1. **bertalign** (3ä¸ªæ–‡ä»¶)
   - encoder.py - ä¿®å¤macOS ARM64ä¸Šçš„SentenceTransformerå´©æºƒ
   - aligner.py - é¿å…Google Translate APIè¶…æ—¶
   - corelib.py - ä¿®å¤macOS ARM64ä¸Šçš„FAISSæ‰¹é‡æœç´¢æŒ‚èµ·

2. **fasttext** (1ä¸ªæ–‡ä»¶)
   - FastText.py - ä¿®å¤numpy 2.xå…¼å®¹æ€§é—®é¢˜

### æœªä¿®æ”¹çš„åŒ…
- âœ… hanlp - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯åŸå§‹æ–‡ä»¶
- âœ… sentence_transformers - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯åŸå§‹æ–‡ä»¶
- âœ… spacy - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯åŸå§‹æ–‡ä»¶
- âœ… å…¶ä»–ä¾èµ–åŒ… - æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯åŸå§‹æ–‡ä»¶

---

---

## ğŸ“¦ æ‰“åŒ…åˆ†å‘

æ‰€æœ‰ä¿®æ”¹å·²æ‰“åŒ…æˆå¯åˆ†å‘çš„PythonåŒ…ï¼Œä½äº`patched_packages/`ç›®å½•ï¼š

### ç”Ÿæˆçš„åŒ…æ–‡ä»¶

1. **bertalign_macos_patched-0.1.0.post1**
   - `.whl` æ–‡ä»¶ (13KB) - æ¨èä½¿ç”¨
   - `.tar.gz` æ–‡ä»¶ (13KB) - æºç åŒ…

2. **fasttext_numpy2_patched-0.9.3.post1**
   - `.whl` æ–‡ä»¶ (18KB) - æ¨èä½¿ç”¨
   - `.tar.gz` æ–‡ä»¶ (16KB) - æºç åŒ…

### å®‰è£…æ–¹æ³•

```bash
# æ–¹æ³•1: ä½¿ç”¨è‡ªåŠ¨å®‰è£…è„šæœ¬
cd patched_packages
./install.sh

# æ–¹æ³•2: æ‰‹åŠ¨å®‰è£…
pip install patched_packages/dist/bertalign_macos_patched-0.1.0.post1-py3-none-any.whl
pip install patched_packages/dist/fasttext_numpy2_patched-0.9.3.post1-py3-none-any.whl
```

### åˆ†äº«æ–¹æ³•

æ•´ä¸ª`patched_packages`ç›®å½•å·²å‹ç¼©ä¸º`patched_packages.tar.gz` (200KB)ï¼Œå¯ä»¥ç›´æ¥åˆ†äº«ç»™å…¶ä»–ç”¨æˆ·ã€‚

è¯¦ç»†ä¿¡æ¯è¯·å‚è§ï¼š
- `patched_packages/README.md` - å®‰è£…å’Œä½¿ç”¨è¯´æ˜
- `patched_packages/PACKAGE_INFO.md` - è¯¦ç»†çš„åŒ…ä¿¡æ¯å’ŒæŠ€æœ¯ç»†èŠ‚

---

**åˆ›å»ºæ—¥æœŸ**: 2025-12-21
**æœ€åæ›´æ–°**: 2025-12-21
**ç»´æŠ¤è€…**: Patrick
**éªŒè¯æ–¹æ³•**: ä½¿ç”¨GitHubåŸå§‹ä»“åº“è¿›è¡Œdiffå¯¹æ¯”
- bertalign: commit 56f2ab5
- fasttext: ä¸»åˆ†æ”¯æœ€æ–°ç‰ˆæœ¬
