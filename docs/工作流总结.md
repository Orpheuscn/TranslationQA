# 翻译质量检查工具 - 工作流总结

## 📋 完整工作流

### 步骤1: 文本预处理和分句

**输入**: 原文文本 (Source) 和译文文本 (Target)

**处理**:
- 使用 `text_splitter.py` 进行自动分句
- 支持 spaCy（英文）、HanLP（中文）或简单规则分句
- 输出: 有序的句子列表

```python
S_Sentences = [S1, S2, S3, ...]
T_Sentences = [T1, T2, T3, ...]
```

### 步骤2: Bertalign软对齐

**配置参数** (优化后):
- `max_align = 6` (最大对齐数，支持复杂N:M对齐)
- `top_k = 5` (top-k候选，增加候选数)
- `score_threshold = 0.15` (分数阈值)
- `skip = -1.0` (跳过惩罚，强惩罚使算法倾向N:M对齐)
- `win = 10` (窗口大小，扩大搜索范围)

**执行**:
- 使用 Bertalign 对句子进行N:M语义对齐
- 使用 LaBSE ONNX 模型生成句子嵌入
- 动态规划算法找到最优对齐路径

**输出**: 对齐组列表
```python
Alignment_Groups = [
    ([S_indices], [T_indices]),
    ...
]
```

### 步骤3: 相似度计算和异常检测

**3.1 计算相似度**:
- 对每个对齐组，使用 LaBSE ONNX 编码句子
- 如果一侧有多个句子（1:N或N:1），计算向量平均值
- 计算余弦相似度: `Sim = dot(src_emb, tgt_emb)`

**3.2 检测异常**:

1. **缺失 (Omission)**: 
   - 检查源句子索引是否都出现在对齐组中
   - 未对齐的源句子标记为"缺失"

2. **增添 (Addition)**:
   - 检查目标句子索引是否都出现在对齐组中
   - 未对齐的目标句子标记为"增添"

3. **相似度低 (Low Similarity)**:
   - 如果 `Sim < 0.7`，标记为"相似度低"

### 步骤4: 格式化输出

**JSON格式**: 结构化数据，包含完整信息

**CSV格式**: 按要求的多行平铺格式

**平铺逻辑**:
```python
max_rows = max(len(S_indices), len(T_indices))

for row_idx in range(max_rows):
    if row_idx == 0:
        # 第一行：显示源文本和目标文本
        S_text = S[S_indices[0]]
        T_text = T[T_indices[0]]
    elif row_idx < len(S_indices):
        # N:1情况：显示后续源文本，目标留空
        S_text = S[S_indices[row_idx]]
        T_text = ""
    elif row_idx < len(T_indices):
        # 1:N情况：显示后续目标文本，源留空
        S_text = ""
        T_text = T[T_indices[row_idx]]
```

## 📊 CSV报告格式示例

| 原文 (Source) | 译文 (Target) | 源索引 | 目标索引 | 相似度 | 异常情况 |
|--------------|--------------|--------|---------|--------|---------|
| Sentence 1   | 句子1        | 0      | 0       | 0.9095 | OK      |
| Sentence 2   | 句子2        | 1      | 1       | 0.7415 | OK      |
| Sentence 3   |              | 2      |         |        | 缺失     |
| Sentence 4   | 句子3        | 3      | 2       | 0.6544 | 相似度低 |
| Sentence 5   |              | 4      |         |        |         |
|              | 句子4        |        | 3       |        | 增添     |

## 🔧 技术实现

### 核心文件

1. **translation_qa_tool.py** (15KB)
   - `TranslationQA` 类：主工具
   - `check_translation()`: 执行完整检查流程
   - `save_report_json()`: 保存JSON报告
   - `save_report_csv()`: 保存CSV报告（多行平铺）
   - `print_summary()`: 打印摘要

2. **labse_onnx_encoder.py** (4.3KB)
   - `LaBSEOnnxEncoder` 类：ONNX编码器
   - `encode_sentences()`: 编码句子为768维向量
   - L2归一化处理

3. **text_splitter.py** (4.8KB)
   - `TextSplitter` 类：分句器
   - 支持 spaCy / HanLP / 简单规则
   - 自动语言检测

4. **test.py** (3.1KB)
   - 测试脚本
   - 包含两个测试用例

### 修补的Bertalign文件

1. **venv/lib/python3.12/site-packages/bertalign/encoder.py**
   - 添加 ONNX 支持
   - 使用 `onnxruntime` 替代 `sentence_transformers`

2. **venv/lib/python3.12/site-packages/bertalign/corelib.py**
   - 修复 FAISS 批量搜索bug
   - 逐个搜索向量（macOS ARM64兼容）

## 🎯 使用示例

```python
from translation_qa_tool import TranslationQA

# 初始化
qa_tool = TranslationQA(
    similarity_threshold=0.7,
    max_align=4,
    score_threshold=0.15
)

# 检查翻译
results = qa_tool.check_translation(
    source_text="Your text here.",
    target_text="你的文本在这里。",
    is_split=False  # 自动分句
)

# 保存报告
qa_tool.save_report_json(results, "report.json")
qa_tool.save_report_csv(results, "report.csv")
```

## 🔧 参数调优过程

### 问题发现

初始参数 (`max_align=4, skip=-0.1`) 导致Bertalign过于保守：
- 将S3,S4,S5分别对齐为 [2,3]→[2] 和 [4,5]→[3]
- 未能识别出4:2对齐 [2,3,4,5]→[2,3]
- 导致相似度低的误报

### 解决方案

通过参数调优找到最佳组合：
- `max_align=6`: 支持更复杂的N:M对齐
- `skip=-1.0`: 强惩罚"跳过"，倾向于合并而非缺失
- `top_k=5, win=10`: 扩大搜索空间

### 优化效果

| 参数组合 | 对齐结果 | 相似度低问题 |
|---------|---------|-------------|
| max_align=4, skip=-0.1 | 6个对齐组 (2:1, 2:1) | 2处 |
| max_align=6, skip=-1.0 | 5个对齐组 (4:2) | 1处 |

**关键改进**: 正确识别了4:2对齐，相似度从0.65提升到0.83！

## ✅ 测试结果

**测试1**: 9句英文 vs 6句中文
- ✅ 对齐成功: 5个对齐组（包含1个4:2对齐）
- ✅ 检测到1处相似度低问题
- ✅ CSV正确展开4:2对齐为多行

**测试2**: 3句英文 vs 3句中文（自动分句）
- ✅ 自动分句成功
- ✅ 对齐成功: 1个对齐组（3:3对齐）
- ✅ 无异常问题

## 📁 最终文件结构

```
语义对齐/
├── labse_onnx/                  # LaBSE ONNX模型
│   ├── model.onnx
│   ├── config.json
│   └── ...
├── venv/                        # Python虚拟环境（已修补Bertalign）
├── translation_qa_tool.py       # 主工具 (15KB)
├── labse_onnx_encoder.py        # ONNX编码器 (4.3KB)
├── text_splitter.py             # 分句模块 (4.8KB)
├── test.py                      # 测试脚本 (3.1KB)
├── README_FINAL.md              # 使用文档
└── 工作流总结.md                 # 本文档
```

## 🎉 项目完成

所有功能已实现并测试通过：
- ✅ 文本分句（spaCy/HanLP/简单规则）
- ✅ N:M句子对齐（Bertalign）
- ✅ 语义相似度计算（LaBSE ONNX + 向量平均）
- ✅ 三种异常检测（缺失、增添、相似度低）
- ✅ 多行平铺CSV格式
- ✅ macOS ARM64兼容性修复

