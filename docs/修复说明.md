# 修复说明 - 2025-12-21

## 🐛 发现的问题

### 1. 分句功能未启用

**问题描述**:
- `app.py` 中 `use_spacy=False, use_hanlp=False`，导致没有使用高级分句
- 传入 `is_split=True`，跳过了分句步骤
- 结果：所有文本被当作单句处理

**影响**:
- 无法正确分句
- 对齐结果不准确
- 无法检测到多句之间的异常

### 2. CSV显示问题

**问题描述**:
- N:M对齐的相似度和异常只在第一行显示
- 其他行显示为空

**影响**:
- 用户看不到完整的相似度信息
- 难以判断对齐质量

### 3. 依赖缺失

**问题描述**:
- `requirements.txt` 缺少 `spacy` 和 `hanlp`

**影响**:
- 无法使用高级分句功能
- 中文分句质量差

---

## ✅ 修复方案

### 1. 启用分句功能

**修改文件**: `app.py`

**修改内容**:
```python
# 修改前
qa_tool = TranslationQA(
    use_spacy=False,
    use_hanlp=False,
    ...
)

results = tool.check_translation(
    source_text=source_text,
    target_text=target_text,
    is_split=True  # 跳过分句
)

# 修改后
qa_tool = TranslationQA(
    use_spacy=True,   # 启用spaCy（欧洲语言）
    use_hanlp=True,   # 启用HanLP（中文）
    ...
)

# 添加语言检测
def detect_language(text):
    import re
    if re.search(r'[\u4e00-\u9fff]', text):
        return 'zh'  # 中文
    else:
        return 'en'  # 欧洲语言

src_lang = detect_language(source_text)
tgt_lang = detect_language(target_text)

results = tool.check_translation(
    source_text=source_text,
    target_text=target_text,
    source_language=src_lang,
    target_language=tgt_lang,
    is_split=False  # 让工具自动分句
)
```

**原理**:
- 根据文本内容自动检测语言（检查是否包含中文字符）
- 中文文本使用HanLP分句
- 欧洲语言文本使用spaCy分句
- 传入 `is_split=False` 让工具执行分句

### 2. 修复CSV显示

**修改文件**: `app.py`

**修改内容**:
```python
# 修改前
# 只在第一行显示相似度和异常
sim_str = f"{similarity:.4f}" if (i == 0 and similarity is not None) else ""
exc_str = exception if i == 0 else ""

# 修改后
# 每一行都显示相似度和异常
sim_str = f"{similarity:.4f}" if similarity is not None else ""
exc_str = exception
```

**原理**:
- N:M对齐的所有行共享同一个相似度值
- 每一行都显示相似度和异常，方便用户查看

### 3. 添加依赖

**修改文件**: `requirements.txt`

**修改内容**:
```
# 添加
spacy>=3.7.0
hanlp>=2.1.0
```

---

## 📋 测试验证

### 1. 安装依赖

```bash
source venv/bin/activate
pip install spacy hanlp
```

### 2. 下载spaCy模型（英文）

```bash
python -m spacy download en_core_web_sm
```

### 3. 重启服务器

```bash
python app.py
```

### 4. 测试分句

**测试用例**:

**原文** (英文，多句):
```
Wandering into the intoxicating world of bizarre and alluring pleasures that is the Tencent App Store, the world's largest digital marketplace, you'll probably experience an initial sense of confusion. Bombarded with gauche images, garish colours and a cacophony of orgasms and other delights, it would be hard not to feel at least somewhat overwhelmed.
```

**译文** (中文，多句):
```
当你漫步进入腾讯应用商店这个令人陶醉的市场，沉浸在其光怪陆离的奇趣内容、令人迷醉的奇幻世界中时，或许你会感到一些困惑。各种俗艳的图片、花哨的色彩、以及各种高潮和其他的愉悦声音，这些都会让你感到有些不知所措。
```

**预期结果**:
- 源文本分句: 2句
- 目标文本分句: 2句
- 对齐组数: 2个
- CSV表格显示每句的相似度

---

## 🎯 修复效果

### 修复前

- ❌ 文本未分句，整段作为一句处理
- ❌ CSV只显示一行
- ❌ 无法检测句子级别的异常
- ❌ 相似度只在第一行显示

### 修复后

- ✅ 文本正确分句（英文用spaCy，中文用HanLP）
- ✅ CSV显示所有句子
- ✅ 可以检测句子级别的异常
- ✅ 每一行都显示相似度和异常

---

## 📝 技术说明

### 语言检测逻辑

```python
def detect_language(text):
    """简单的语言检测：检查是否包含中文字符"""
    import re
    if re.search(r'[\u4e00-\u9fff]', text):
        return 'zh'  # 中文
    else:
        return 'en'  # 欧洲语言
```

**原理**:
- 使用正则表达式检查文本中是否包含中文字符（Unicode范围：U+4E00 到 U+9FFF）
- 如果包含中文字符，判定为中文（使用HanLP分句）
- 否则判定为欧洲语言（使用spaCy分句）

### 分句工具选择

| 语言类型 | 分句工具 | 说明 |
|---------|---------|------|
| 中文 (zh) | HanLP | 专门针对中文优化，分句准确 |
| 欧洲语言 (en) | spaCy | 支持多种欧洲语言，分句准确 |
| 未安装 | 简单规则 | 基于标点符号的简单分句 |

### 工作流程

```
用户输入文本
  ↓
自动检测语言 (detect_language)
  ↓
选择分句工具
  ├─ 中文 → HanLP
  └─ 欧洲语言 → spaCy
  ↓
分句 (TextSplitter.split_sentences)
  ↓
对齐 (Bertalign)
  ↓
计算相似度
  ↓
检测异常
  ↓
生成CSV报告
```

---

## 🚀 后续优化建议

### 1. 支持更多语言

可以扩展语言检测逻辑，支持更多语言：
- 日文、韩文
- 法语、德语、西班牙语等

### 2. 用户可选语言

在网页界面添加语言选择下拉框，让用户手动指定语言

### 3. 分句质量提示

在结果中显示使用的分句工具，提示用户分句质量

---

## ✅ 修复完成

所有问题已修复，现在工具可以：
- ✅ 自动检测语言
- ✅ 使用对应的分句工具（spaCy/HanLP）
- ✅ 正确分句
- ✅ 显示完整的相似度信息
- ✅ 检测句子级别的异常

